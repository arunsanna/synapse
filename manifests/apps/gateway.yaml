apiVersion: v1
kind: ConfigMap
metadata:
  name: synapse-gateway-config
  namespace: llm-infra
  labels:
    app: synapse-gateway
    app.kubernetes.io/part-of: synapse
data:
  backends.yaml: |
    # Synapse backend registry â€” mounted at /config/backends.yaml
    backends:
      llama-embed:
        url: http://llama-embed.llm-infra.svc.cluster.local:8081
        type: openai-compatible
        health: /health

      llama-router:
        url: http://llama-router.llm-infra.svc.cluster.local:8082
        type: openai-compatible
        health: /health

      chatterbox-tts:
        url: http://chatterbox-tts.llm-infra.svc.cluster.local:8004
        type: chatterbox
        health: /api/ui/initial-data

      whisper-stt:
        url: http://whisper-stt.llm-infra.svc.cluster.local:8000
        type: faster-whisper
        health: /health

      pyannote-speaker:
        url: http://pyannote-speaker.llm-infra.svc.cluster.local:8000
        type: pyannote
        health: /health

      deepfilter-audio:
        url: http://deepfilter-audio.llm-infra.svc.cluster.local:8000
        type: deepfilter
        health: /health

    routes:
      /v1/embeddings: llama-embed
      /v1/chat/completions: llama-router
      /models: llama-router
      /models/load: llama-router
      /models/unload: llama-router
      /v1/models: llama-router
      /tts/*: chatterbox-tts
      /stt/*: whisper-stt
      /speakers/*: pyannote-speaker
      /audio/*: deepfilter-audio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: synapse-gateway
  namespace: llm-infra
  labels:
    app: synapse-gateway
    app.kubernetes.io/part-of: synapse
    app.kubernetes.io/component: gateway
spec:
  replicas: 1
  selector:
    matchLabels:
      app: synapse-gateway
  template:
    metadata:
      labels:
        app: synapse-gateway
        app.kubernetes.io/part-of: synapse
    spec:
      serviceAccountName: synapse-gateway
      containers:
        - name: gateway
          image: registry.arunlabs.com/synapse-gateway:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 8000
              name: http
          env:
            - name: SYNAPSE_GATEWAY_CONFIG_PATH
              value: /config/backends.yaml
            - name: SYNAPSE_VOICE_LIBRARY_DIR
              value: /data/voices
            - name: SYNAPSE_LLAMA_ROUTER_DEPLOYMENT_NAMESPACE
              value: llm-infra
            - name: SYNAPSE_LLAMA_ROUTER_DEPLOYMENT_NAME
              value: llama-router
            - name: SYNAPSE_LLAMA_ROUTER_CONTAINER_NAME
              value: llama-server
            - name: SYNAPSE_RUNTIME_RECONFIGURE_TIMEOUT_SECONDS
              value: "300"
            - name: SYNAPSE_LOG_LEVEL
              value: INFO
            - name: SYNAPSE_TERMINAL_FEED_MODE
              value: live
            - name: SYNAPSE_TERMINAL_FEED_BUS_MODE
              value: redis
            - name: SYNAPSE_TERMINAL_FEED_REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: synapse-gateway-secrets
                  key: terminal_feed_redis_url
            - name: SYNAPSE_TERMINAL_FEED_REDIS_CHANNEL
              value: synapse:terminal_feed
            - name: SYNAPSE_TERMINAL_FEED_REDIS_CONNECT_TIMEOUT_SECONDS
              value: "5"
            - name: SYNAPSE_TERMINAL_FEED_BUFFER_SIZE
              value: "800"
            - name: SYNAPSE_TERMINAL_FEED_SUBSCRIBER_QUEUE_SIZE
              value: "300"
            - name: SYNAPSE_TERMINAL_FEED_BACKLOG_LINES
              value: "100"
            - name: SYNAPSE_TERMINAL_FEED_KEEPALIVE_SECONDS
              value: "15"
            - name: SYNAPSE_TERMINAL_FEED_MAX_LINE_CHARS
              value: "1200"
            - name: SYNAPSE_TERMINAL_FEED_DEFAULT_LEVEL
              value: INFO
            - name: SYNAPSE_INSTANCE_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          resources:
            requests:
              memory: 256Mi
              cpu: "0.5"
            limits:
              memory: 1Gi
              cpu: "2"
          volumeMounts:
            - name: config
              mountPath: /config/backends.yaml
              subPath: backends.yaml
              readOnly: true
            - name: voices
              mountPath: /data/voices
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 30
      volumes:
        - name: config
          configMap:
            name: synapse-gateway-config
        - name: voices
          persistentVolumeClaim:
            claimName: synapse-voices
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: synapse-gateway
  namespace: llm-infra
  labels:
    app: synapse-gateway
    app.kubernetes.io/part-of: synapse
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: synapse-gateway-llama-router-runtime
  namespace: llm-infra
  labels:
    app: synapse-gateway
    app.kubernetes.io/part-of: synapse
rules:
  - apiGroups: ["apps"]
    resources: ["deployments"]
    resourceNames: ["llama-router"]
    verbs: ["get", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: synapse-gateway-llama-router-runtime
  namespace: llm-infra
  labels:
    app: synapse-gateway
    app.kubernetes.io/part-of: synapse
subjects:
  - kind: ServiceAccount
    name: synapse-gateway
    namespace: llm-infra
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: synapse-gateway-llama-router-runtime
---
apiVersion: v1
kind: Service
metadata:
  name: synapse-gateway
  namespace: llm-infra
  labels:
    app: synapse-gateway
    app.kubernetes.io/part-of: synapse
spec:
  selector:
    app: synapse-gateway
  ports:
    - port: 8000
      targetPort: 8000
      name: http
  type: ClusterIP
